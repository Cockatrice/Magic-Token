name: Picture Health

on:
  pull_request:
  workflow_dispatch:
  schedule:
    # Runs at the start of each month (UTC)
    - cron: '0 0 1 * *'

jobs:
  check_urls:
    # Do not run the scheduled workflow on forks
    if: ( github.event_name != 'schedule' || github.repository_owner == 'Cockatrice' )

    name: Check image links
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Lychee responses cache
        uses: actions/cache@v3
        with:
          path: .lycheecache
          key: cache-lychee-${{ github.sha }}
          restore-keys: cache-lychee-

      - name: Install XMLStarlet
        shell: bash
        run: sudo apt-get install xmlstarlet 

      - name: Extract URLs from tokens.xml
        if: always()
        id: tokens_pic_urls
        shell: bash
        run: xmlstarlet sel -t -v "//set/@picURL" tokens.xml | tee tokens_pic_urls.txt

      - name: Extract URLs from challenge_tokens.xml
        # Forcefully skipping, see https://github.com/Cockatrice/Magic-Token/issues/47
        # if: always()
        if: false
        id: challenge_pic_urls
        shell: bash
        run: xmlstarlet sel -t -v "//set/@picURL" challenge_tokens.xml | tee challenge_pic_urls.txt

      - name: Check tokens.xml URLs
        uses: lycheeverse/lychee-action@v1.5.0
        if: steps.tokens_pic_urls.outcome == 'success'
        with:
          args: '--no-progress --require-https --cache --max-cache-age 1h -- tokens_pic_urls.txt'
          fail: true
          jobSummary: true
          lycheeVersion: 0.9.0

      - name: Check challenge_tokens.xml URLs
        uses: lycheeverse/lychee-action@v1.5.0
        if: steps.challenge_pic_urls.outcome == 'success'
        with:
          args: '--no-progress --require-https --cache --max-cache-age 1h -- challenge_pic_urls.txt'
          fail: true
          jobSummary: true
          lycheeVersion: 0.9.0

      - name: List duplicated image links
        if: steps.tokens_pic_urls.outcome == 'success'
        shell: bash
        # Remove blank lines | sort | count and list duplicates
        run: grep . tokens_pic_urls.txt | sort | uniq -cd

      - name: Image hosts statistics
        if: steps.tokens_pic_urls.outcome == 'success'
        shell: bash
        # Extract domains from URLs | remove blank lines | sort | count and list | sort descending
        run: awk -F/ '{print $3}' tokens_pic_urls.txt | grep . | sort | uniq -c | sort -nr
